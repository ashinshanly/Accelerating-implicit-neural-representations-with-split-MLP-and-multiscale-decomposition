# Accelerating Implicit Neural Representations using Split MLP and Multiscale Decomposition

Implicit Neural Representation (INR) is an emerging signal representation and rendering technique. These representations are continuous, implicit and differentiable. Their primary advantages are memory efficiency with high spatial resolution and the ability to be incorporated into pipelines based on differentiable learning. However, neural scene representations are slow and cannot represent complex scenes. In this work, we aim to speed up the training time for implicit neural representation networks without compromising the quality of the reconstructed signal. We propose an input-split network architecture that flexibly distributes network resources during training based on the intricacy of the input signal at the given locality. The model learns each underlying dimension of the input coordinates separately and partitions the input space in a multiscale fashion. We show results on large-scale images such as the 64 MP Pluto image captured by the New Horizons space probe and on complex Stanford 3D models varying the maximum number of blocks used in the partition. We present a detailed comparison of results indicating training time speedups of up to ∼ 37.8% more than the state-of-the-art approaches for 1 MP images, ∼ 25% more for 64 MP large images, and ∼ 23.72% more for 3D signals.
